
import torch
# from haystack.components.generators import HuggingFaceLocalGenerator



def loadModel(knowledge_base=None):
    

    # generator = HuggingFaceLocalGenerator(
    # model="meta-llama/Llama-3.2-3B-Instruct",
    # huggingface_pipeline_kwargs={"device_map":"auto",
    #                              "torch_dtype":torch.bfloat16},
    # generation_kwargs={"max_new_tokens": 256})

    # generator.warm_up()



    return None
